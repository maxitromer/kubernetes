fullnameOverride: prometheus

alertmanager:
  fullnameOverride: alertmanager
  enabled: true
  ingress:
    enabled: false
  alertmanagerSpec:
    ## Storage is the definition of how storage will be used by the Alertmanager instances.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md
    ##
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: longhorn-hdd-2-replicas
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 5Gi
    #   selector: {}


grafana:
  enabled: true
  fullnameOverride: grafana
  forceDeployDatasources: false
  forceDeployDashboards: false
  defaultDashboardsEnabled: true
  defaultDashboardsTimezone: utc
  persistence:
    enabled: true
    # type: sts
    storageClassName: "longhorn-hdd-1-replica"
    accessModes:
      - ReadWriteOnce
    size: 20Gi
  serviceMonitor:
    enabled: true
  admin:
    existingSecret: grafana-admin-credentials
    userKey: admin-user
    passwordKey: admin-password

kubeApiServer:
  enabled: true

kubelet:
  enabled: true
  serviceMonitor:
    metricRelabelings:
      - action: replace
        sourceLabels:
          - node
        targetLabel: instance

kubeControllerManager:
  enabled: true
  endpoints: # ips of servers 
    - 10.14.56.11
    - 10.14.56.12
    - 10.14.56.13
    - 10.14.56.201
    - 10.14.56.231               

coreDns:
  enabled: true

kubeDns:
  enabled: false

kubeEtcd:
  enabled: true
  endpoints: # ips of servers
    - 10.14.56.11
    - 10.14.56.12
    - 10.14.56.13
    - 10.14.56.201
    - 10.14.56.231
  service:
    enabled: true
    port: 2381
    targetPort: 2381

kubeScheduler:
  enabled: true
  endpoints: # ips of servers
    - 10.14.56.11
    - 10.14.56.12
    - 10.14.56.13
    - 10.14.56.201
    - 10.14.56.231

kubeProxy:
  enabled: true
  endpoints: # ips of servers
    - 10.14.56.11
    - 10.14.56.12
    - 10.14.56.13
    - 10.14.56.201
    - 10.14.56.231

kubeStateMetrics:
  enabled: true

kube-state-metrics:
  fullnameOverride: kube-state-metrics
  selfMonitor:
    enabled: true
  prometheus:
    monitor:
      enabled: true
      relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels:
            - __meta_kubernetes_pod_node_name
          targetLabel: kubernetes_node

nodeExporter:
  enabled: true
  serviceMonitor:
    relabelings:
      - action: replace
        regex: (.*)
        replacement: $1
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: kubernetes_node

prometheus-node-exporter:
  fullnameOverride: node-exporter
  podLabels:
    jobLabel: node-exporter
  extraArgs:
    - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
    - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
  service:
    portName: http-metrics
  prometheus:
    monitor:
      enabled: true
      relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels:
            - __meta_kubernetes_pod_node_name
          targetLabel: kubernetes_node
  resources:
    requests:
      memory: 512Mi
      cpu: 250m
    limits:
      memory: 2048Mi

prometheusOperator:
  enabled: true
  prometheusConfigReloader:
    resources:
      requests:
        cpu: 100m
        memory: 50Mi
      limits:
        memory: 500Mi

prometheus:
  enabled: true
  prometheusSpec:
    replicas: 1
    replicaExternalLabelName: "replica"
    ruleSelectorNilUsesHelmValues: false
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    probeSelectorNilUsesHelmValues: false
    retention: 30d
    retentionSize: "90GB"
    enableAdminAPI: true
    walCompression: true
    scrapeInterval: 30s
    evaluationInterval: 30s

    additionalScrapeConfigs:
      - job_name: 'moco-controller'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_label_app_kubernetes_io_component, __meta_kubernetes_pod_container_port_name]
            action: keep
            regex: databases;moco-controller;metrics

      - job_name: 'moco-agent'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name, __meta_kubernetes_pod_container_port_name, __meta_kubernetes_pod_label_statefulset_kubernetes_io_pod_name]
            action: keep
            regex: mysql;agent-metrics;moco-.*
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace

      - job_name: 'moco-mysql'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name, __meta_kubernetes_pod_container_port_name, __meta_kubernetes_pod_label_statefulset_kubernetes_io_pod_name]
            action: keep
            regex: mysql;mysqld-metrics;moco-.*
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_instance]
            action: replace
            target_label: name
          - source_labels: [__meta_kubernetes_pod_label_statefulset_kubernetes_io_pod_name]
            action: replace
            target_label: index
            regex: .*-([0-9])
          - source_labels: [__meta_kubernetes_pod_label_moco_cybozu_com_role]
            action: replace
            target_label: role

    ## Prometheus StorageSpec for persistent data
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md
    ##
    storageSpec:
    ## Using PersistentVolumeClaim
      volumeClaimTemplate:
        spec:
          storageClassName: longhorn-hdd-1-replica # longhorn-hdd-2-replicas
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 100Gi
    #   selector: {}
    # affinity:
    #   nodeAffinity:
    #     preferredDuringSchedulingIgnoredDuringExecution:
    #     - weight: 80
    #       preference:
    #         matchExpressions:
    #         - key: no-arm-enabled
    #           operator: Exists
    #   requiredDuringSchedulingIgnoredDuringExecution:
    #     nodeSelectorTerms:
    #     - matchExpressions:
    #       - key: no-arm-enabled
    #         operator: Exists

    # tolerations:
    # - key: "no-arm-enabled"
    #   operator: "Exists"
    #   effect: "NoSchedule"
    # - key: "no-arm32-enabled"
    #   operator: "Exists"
    #   effect: "NoSchedule"      



thanosRuler:
  enabled: false